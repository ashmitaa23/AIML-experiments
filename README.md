• Dimensionality Reduction: The data was reduced from 10 
original features to a lower-dimensional space while retaining 
about 95% of the variance, showing the effectiveness of PCA in 
reducing complexity. 
• Class Separability: When plotted, the transformed data in the 
reduced two-dimensional space showed reasonable separation 
between classes, indicating PCA's success in preserving 
structure relevant to classification. 
• Data Visualization: PCA enabled easier visualization, as 
projecting the data into two dimensions made it possible to 
observe relationships and clustering among different classes. 
• Efficiency in Computation: By reducing the number of features, 
PCA helps in minimizing computational costs for future machine 
learning tasks, especially for large datasets. 
CONCLUSION: 
PCA successfully reduced the dimensions of the dataset while 
retaining crucial variance. This transformation simplifies data 
representation, making it suitable for visualization and preprocessing 
in machine learning tasks. 
